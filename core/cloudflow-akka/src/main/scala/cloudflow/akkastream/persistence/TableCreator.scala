/*
 * Copyright (C) 2016-2020 Lightbend Inc. <https://www.lightbend.com>
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package cloudflow.akkastream.persistence

// Adopted from io.cloudstate.proxy.jdbc.SlickEnsureTablesExistReadyCheck, which is adopted from
// from https://github.com/lagom/lagom/blob/60897ef752ddbfc28553d3726b8fdb830a3ebdc4/persistence-jdbc/core/src/main/scala/com/lightbend/lagom/internal/persistence/jdbc/SlickProvider.scala

import java.sql.Connection

import akka.Done
import akka.actor.ActorSystem
import akka.persistence.jdbc.config.{ ConfigKeys, _ }
import akka.persistence.jdbc.journal.dao.JournalTables
import akka.persistence.jdbc.snapshot.dao.SnapshotTables
import akka.persistence.jdbc.util.SlickExtension
import com.typesafe.config._
import net.ceedubs.ficus.Ficus._
import org.slf4j.LoggerFactory
import slick.jdbc._
import slick.jdbc.meta.MTable

import scala.collection.JavaConverters._
import scala.concurrent.Await
import scala.concurrent.duration.Duration
import scala.util._

object TableCreator {

  private val SLICK_DATABASE  = "akka-persistence-jdbc.shared-databases.slick"
  private val AUTO_CREATE_KEY = "auto-create-tables"
  private val log             = LoggerFactory.getLogger(this.getClass)

  def createTables(system: ActorSystem): Unit = {

    val jdbc = system.settings.config.as[Option[Config]](SLICK_DATABASE)
    jdbc match {
      case Some(config) => // This is JDBC
        val create = config.as[Option[Boolean]](AUTO_CREATE_KEY).getOrElse(false)
        if (create)
          createTablesInternal(system)
      case _ =>
    }
  }

  private def createTablesInternal(system: ActorSystem): Unit = {

    implicit val ec = system.dispatcher

    // Get a hold of the akka-jdbc slick database instance
    val db = SlickExtension(system).database(ConfigFactory.parseMap(Map(ConfigKeys.useSharedDb -> "slick").asJava))

    val dbprofile = db.profile

    import dbprofile.api._

    // Get configurations
    val journalCfg  = new JournalTableConfiguration(system.settings.config.getConfig("jdbc-read-journal"))
    val snapshotCfg = new SnapshotTableConfiguration(system.settings.config.getConfig("jdbc-snapshot-store"))

    // Get tables
    val journalTables = new JournalTables {
      override val journalTableCfg: JournalTableConfiguration = journalCfg
      override val profile: JdbcProfile                       = dbprofile
    }

    val snapshotTables = new SnapshotTables {
      override val snapshotTableCfg: SnapshotTableConfiguration = snapshotCfg
      override val profile: JdbcProfile                         = dbprofile
    }

    // Get JDBC statements
    val journalStatements =
      dbprofile match {
        case H2Profile =>
          // Work around https://github.com/slick/slick/issues/763
          journalTables.JournalTable.schema.createStatements
            .map(_.replace("GENERATED BY DEFAULT AS IDENTITY(START WITH 1)", "AUTO_INCREMENT"))
            .toSeq
        case MySQLProfile =>
          // Work around https://github.com/slick/slick/issues/1437
          journalTables.JournalTable.schema.createStatements
            .map(_.replace("AUTO_INCREMENT", "AUTO_INCREMENT UNIQUE"))
            .toSeq
        case _ => journalTables.JournalTable.schema.createStatements.toSeq
      }
    val snapshotStatements = snapshotTables.SnapshotTable.schema.createStatements.toSeq

    Await.result(createTablesTask(), Duration.Inf)

    // Create tables
    def createTablesTask() =
      db.database.run {
        for {
          _ <- createTable(journalStatements, tableExists(journalCfg.schemaName, journalCfg.tableName))
          _ <- createTable(snapshotStatements, tableExists(snapshotCfg.schemaName, snapshotCfg.tableName))
        } yield Done.getInstance()
      }

    // Create tables
    def createTable(schemaStatements: Seq[String], tableExists: (Vector[MTable], Option[String]) => Boolean) =
      for {
        currentSchema <- getCurrentSchema
        tables        <- getTables(currentSchema)
        _             <- createTableInternal(tables, currentSchema, schemaStatements, tableExists)
      } yield Done.getInstance()

    // Internal create tables
    def createTableInternal(tables: Vector[MTable],
                            currentSchema: Option[String],
                            schemaStatements: Seq[String],
                            tableExists: (Vector[MTable], Option[String]) => Boolean) =
      if (tableExists(tables, currentSchema)) {
        DBIO.successful(())
      } else {
        if (log.isDebugEnabled) {
          log.debug("Creating table, executing: " + schemaStatements.mkString("; "))
        }

        DBIO
          .sequence(schemaStatements.map { s =>
            SimpleDBIO { ctx =>
              val stmt = ctx.connection.createStatement()
              try {
                stmt.executeUpdate(s)
              } finally {
                stmt.close()
              }
            }
          })
          .asTry
          .flatMap {
            case Success(_) => DBIO.successful(())
            case Failure(f) =>
              getTables(currentSchema).map { tables =>
                if (tableExists(tables, currentSchema)) {
                  log.debug("Table creation failed, but table existed after it was created, ignoring failure", f)
                  ()
                } else {
                  throw f
                }
              }
          }
      }

    // Get existing tables
    def getTables(currentSchema: Option[String]) =
      // Calling MTable.getTables without parameters fails on MySQL
      // See https://github.com/lagom/lagom/issues/446
      // and https://github.com/slick/slick/issues/1692
      dbprofile match {
        case _: MySQLProfile =>
          MTable.getTables(currentSchema, None, Option("%"), None)
        case _ =>
          MTable.getTables(None, currentSchema, Option("%"), None)
      }

    // Get current schema
    def getCurrentSchema: DBIO[Option[String]] =
      SimpleDBIO(ctx => tryGetSchema(ctx.connection).getOrElse(null)).flatMap { schema =>
        if (schema == null) {
          // Not all JDBC drivers support the getSchema method:
          // some always return null.
          // In that case, fall back to vendor-specific queries.
          dbprofile match {
            case _: H2Profile =>
              sql"SELECT SCHEMA();".as[String].headOption
            case _: MySQLProfile =>
              sql"SELECT DATABASE();".as[String].headOption
            case _: PostgresProfile =>
              sql"SELECT current_schema();".as[String].headOption
            case _ =>
              DBIO.successful(None)
          }
        } else DBIO.successful(Some(schema))
      }

    // Some older JDBC drivers don't implement Connection.getSchema
    // (including some builds of H2). This causes them to throw an
    // AbstractMethodError at runtime.
    // Because Try$.apply only catches NonFatal errors, and AbstractMethodError
    // is considered fatal, we need to construct the Try explicitly.
    def tryGetSchema(connection: Connection): Try[String] =
      try Success(connection.getSchema)
      catch {
        case e: AbstractMethodError =>
          Failure(new IllegalStateException("Database driver does not support Connection.getSchema", e))
      }

    // Check if table exists
    def tableExists(schemaName: Option[String], tableName: String)(tables: Vector[MTable], currentSchema: Option[String]): Boolean =
      tables.exists { t =>
        dbprofile match {
          case _: MySQLProfile =>
            t.name.catalog.orElse(currentSchema) == schemaName.orElse(currentSchema) && t.name.name == tableName
          case _ =>
            t.name.schema.orElse(currentSchema) == schemaName.orElse(currentSchema) && t.name.name == tableName
        }
      }
  }
}
